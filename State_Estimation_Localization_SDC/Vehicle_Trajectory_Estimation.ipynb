{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "-----\n",
    "\n",
    "In this assignment you will recursively estimate the position of a vehicle along a trajectory using available measurements and a motion model. \n",
    "\n",
    "The vehicle is equipped with a very simple type of LIDAR sensor, which returns range and bearing measurements corresponding to individual landmarks in the environment. The global positions of the landmarks are assumed to be known beforehand. We will also assume known data association, that is, which measurment belong to which landmark.\n",
    "\n",
    "## Motion and Measurement Models\n",
    "-----\n",
    "\n",
    "### Motion Model\n",
    "\n",
    "The vehicle motion model recieves linear and angular velocity odometry readings as inputs, and outputs the state (i.e., the 2D pose) of the vehicle:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{x}_{k} &= \\mathbf{x}_{k-1} + T\n",
    "\\begin{bmatrix}\n",
    "\\cos\\theta_{k-1} &0 \\\\\n",
    "\\sin\\theta_{k-1} &0 \\\\\n",
    "0 &1\n",
    "\\end{bmatrix}\n",
    "\\left(\n",
    "\\begin{bmatrix}\n",
    "v_k \\\\\n",
    "\\omega_k\n",
    "\\end{bmatrix}\n",
    "+ \\mathbf{w}_k\n",
    "\\right)\n",
    "\\, , \\, \\, \\, \\, \\, \\mathbf{w}_k = \\mathcal{N}\\left(\\mathbf{0}, \\mathbf{Q}\\right)\n",
    "\\end{align}\n",
    "\n",
    "- $\\mathbf{x}_k = \\left[ x \\, y \\, \\theta \\right]^T$ is the current 2D pose of the vehicle\n",
    "- $v_k$ and $\\omega_k$ are the linear and angular velocity odometry readings, which we use as inputs to the model\n",
    "\n",
    "The process noise $\\mathbf{w}_k$ has a (zero mean) normal distribution with a constant covariance $\\mathbf{Q}$.\n",
    "\n",
    "### Measurement Model\n",
    "\n",
    "The measurement model relates the current pose of the vehicle to the LIDAR range and bearing measurements $\\mathbf{y}^l_k = \\left[r \\, \\phi \\right]^T$.\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{y}^l_k =\n",
    "\\begin{bmatrix}\n",
    "\\sqrt{(x_l - x_k - d\\cos\\theta_{k})^2 + (y_l - y_k - d\\sin\\theta_{k})^2} \\\\\n",
    "atan2\\left(y_l - y_k - d\\sin\\theta_{k},x_l - x_k - d\\cos\\theta_{k}\\right) - \\theta_k\n",
    "\\end{bmatrix}\n",
    "+\n",
    "\\mathbf{n}^l_k\n",
    "\\, , \\, \\, \\, \\, \\, \\mathbf{n}^l_k = \\mathcal{N}\\left(\\mathbf{0}, \\mathbf{R}\\right)\n",
    "\\end{align}\n",
    "\n",
    "- $x_l$ and $y_l$ are the ground truth coordinates of the landmark $l$\n",
    "- $x_k$ and $y_k$ and $\\theta_{k}$ represent the current pose of the vehicle\n",
    "- $d$ is the known distance between robot center and laser rangefinder (LIDAR)\n",
    "\n",
    "The landmark measurement noise $\\mathbf{n}^l_k$ has a (zero mean) normal distribution with a constant covariance $\\mathbf{R}$.\n",
    "\n",
    "## Getting Started\n",
    "-----\n",
    "\n",
    "Since the models above are nonlinear, we recommend using the extended Kalman filter (EKF) as the state estimator.\n",
    "Specifically, you will need to provide code implementing the following steps:\n",
    "- the prediction step, which uses odometry measurements and the motion model to produce a state and covariance estimate at a given timestep, and\n",
    "- the correction step, which uses the range and bearing measurements provided by the LIDAR to correct the pose and pose covariance estimates\n",
    "\n",
    "### Unpack the Data\n",
    "First, let's unpack the available data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from numpy.linalg import inv\n",
    "\n",
    "\n",
    "with open('data/data.pickle', 'rb') as f:\n",
    "    data = pickle.load(f)\n",
    "\n",
    "t = data['t']  # timestamps [s]\n",
    "\n",
    "x_init  = data['x_init'] # initial x position [m]\n",
    "y_init  = data['y_init'] # initial y position [m]\n",
    "th_init = data['th_init'] # initial theta position [rad]\n",
    "\n",
    "# input signal\n",
    "v  = data['v']  # translational velocity input [m/s]\n",
    "om = data['om']  # rotational velocity input [rad/s]\n",
    "\n",
    "# bearing and range measurements, LIDAR constants\n",
    "b = data['b']  # bearing to each landmarks center in the frame attached to the laser [rad]\n",
    "r = data['r']  # range measurements [m]\n",
    "l = data['l']  # x,y positions of landmarks [m]\n",
    "d = data['d']  # distance between robot center and laser rangefinder [m]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that distance from the LIDAR frame to the robot center is provided and loaded as an array into the `d` variable.\n",
    "\n",
    "### Ground Truth\n",
    "If available, it is useful to plot the ground truth position and orientation before starting the assignment.\n",
    "\n",
    "<table><tr>\n",
    "<td> <img src=\"data/gtruth.png\" alt=\"Ground Truth\" width=\"350\"/> </td>\n",
    "<td> <img src=\"data/gtruth2.png\" alt=\"Ground Truth\" width=\"350\"/> </td>\n",
    "</tr></table>\n",
    "\n",
    "Notice that the orientation values are wrapped to the $\\left[-\\pi,\\pi\\right]$ range in radians."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initializing Parameters\n",
    "\n",
    "Now that our data is loaded, we can begin getting things set up for our solver. One of the\n",
    "most important aspects of designing a filter is determining the input and measurement noise covariance matrices, as well as the initial state and covariance values. We set the values here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_var = 0.01  # translation velocity variance  \n",
    "om_var = 0.01  # rotational velocity variance \n",
    "r_var = 0.1  # range measurements variance\n",
    "b_var = 0.1  # bearing measurement variance\n",
    "\n",
    "Q_km = np.diag([v_var, om_var]) # input noise covariance \n",
    "cov_y = np.diag([r_var, b_var])  # measurement noise covariance \n",
    "\n",
    "x_est = np.zeros([len(v), 3])  # estimated states, x, y, and theta\n",
    "P_est = np.zeros([len(v), 3, 3])  # state covariance matrices\n",
    "\n",
    "x_est[0] = np.array([x_init, y_init, th_init]) # initial state\n",
    "P_est[0] = np.diag([1, 1, 0.1]) # initial state covariance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_est[6]@P_est[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "P_est[6,:,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Remember:** that it is neccessary to tune the measurement noise variances `r_var`, `b_var` in order for the filter to perform well!\n",
    "\n",
    "In order for the orientation estimates to coincide with the bearing measurements, it is also neccessary to wrap all estimated $\\theta$ values to the $(-\\pi , \\pi]$ range."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wraps angle to (-pi,pi] range\n",
    "def wraptopi(x):\n",
    "    if x > np.pi:\n",
    "        x = x - (np.floor(x / (2 * np.pi)) + 1) * 2 * np.pi\n",
    "    elif x < -np.pi:\n",
    "        x = x + (np.floor(x / (-2 * np.pi)) + 1) * 2 * np.pi\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Correction Step\n",
    "-----\n",
    "First, let's implement the measurement update function, which takes an available landmark measurement $l$ and updates the current state estimate $\\mathbf{\\check{x}}_k$.\n",
    "For each landmark measurement received at a given timestep $k$, you should implement the following steps:\n",
    "\n",
    "- Compute the measurement model Jacobians at $\\mathbf{\\check{x}}_{k}$\n",
    "\\begin{align}\n",
    "\\mathbf{y}^l_k = &\\mathbf{h}(\\mathbf{x}_{k}, \\mathbf{n}^l_k) \\\\\\\\\n",
    "\\mathbf{H}_{k} = \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{x}_{k}}\\bigg|_{\\mathbf{\\check{x}}_{k},0}& \\, , \\, \\, \\, \\,\n",
    "\\mathbf{M}_{k} = \\frac{\\partial \\mathbf{h}}{\\partial \\mathbf{n}_{k}}\\bigg|_{\\mathbf{\\check{x}}_{k},0} \\, .\n",
    "\\end{align}\n",
    "- Compute the Kalman Gain\n",
    "\\begin{align}\n",
    "\\mathbf{K}_k &= \\mathbf{\\check{P}}_k \\mathbf{H}_k^T \\left(\\mathbf{H}_k \\mathbf{\\check{P}}_k \\mathbf{H}_k^T + \\mathbf{M}_k \\mathbf{R}_k \\mathbf{M}_k^T \\right)^{-1} \n",
    "\\end{align}\n",
    "- Correct the predicted state\n",
    "\\begin{align}\n",
    "\\mathbf{\\check{y}}^l_k &= \\mathbf{h}\\left(\\mathbf{\\check{x}}_k, \\mathbf{0}\\right) \\\\\n",
    "\\mathbf{\\hat{x}}_k &= \\mathbf{\\check{x}}_k + \\mathbf{K}_k \\left(\\mathbf{y}^l_k - \\mathbf{\\check{y}}^l_k\\right)\n",
    "\\end{align}\n",
    "- Correct the covariance\n",
    "\\begin{align}\n",
    "\\mathbf{\\hat{P}}_k &= \\left(\\mathbf{I} - \\mathbf{K}_k \\mathbf{H}_k \\right)\\mathbf{\\check{P}}_k\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurementModel(x_check, lk):\n",
    "    \"\"\"\n",
    "    The measurement model relates the current state of the vehicle with range and bearing to landmarks.\n",
    "    This function calculates the measurement estimate using the measurement model.\n",
    "    Input: it uses state estimates (x_check) and landmark positions (lk) at a time instant k.\n",
    "    Output: measurement prediction as a function of the current state x_check.\n",
    "    \"\"\"\n",
    "    # measurement components in x and y directions\n",
    "    A = lk[0] - x_check[0] - d[0] * np.cos(x_check[2])\n",
    "    B = lk[1] - x_check[1] - d[1] * np.sin(x_check[2])\n",
    "    \n",
    "    # measurement estimate\n",
    "    y_check = np.array([[np.sqrt(A**2 + B**2)], [np.arctan2(B, A) - x_check[2]]])\n",
    "    \n",
    "    return y_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def measurement_update(lk, rk, bk, P_check, x_check):\n",
    "    \n",
    "    # 1. Compute measurement Jacobian\n",
    "    \n",
    "    # wrap bearing estimates to (-pi, pi)\n",
    "    x_check[2] = wraptopi(x_check[2])\n",
    "    # measurement components in x and y directions\n",
    "    A = lk[0] - x_check[0] - d[0] * np.cos(x_check[2])\n",
    "    B = lk[1] - x_check[1] - d[1] * np.sin(x_check[2])\n",
    "    \n",
    "    # Jacobian matrix components for the measurement model\n",
    "    H_11 = -A / np.sqrt(A**2 + B**2) # parital derivative of y_k[0] w.r.t x_check[0]\n",
    "    H_12 = -B / np.sqrt(A**2 + B**2) # partial derivatieve of y_k[0] w.r.t. x_check[1]\n",
    "    H_13 = (d*(A*np.sin(x_check[2]) - B*np.cos(x_check[2]))) / np.sqrt(A**2 + B**2) # partial drv. of y_k[0] w.r.t. x_check[2]\n",
    "    \n",
    "    H_21 = B / (A**2 + B**2) # parital derivative of y_k[1] w.r.t x_check[0]\n",
    "    H_22 = -A / (A**2 + B**2) # parital derivative of y_k[1] w.r.t x_check[1]\n",
    "    H_23 = (-d*(A*np.cos(x_check[2]) + B*np.sin(x_check[2]))) / (A**2 + B**2) # parital derivative of y_k[1] w.r.t x_check[2]\n",
    "    \n",
    "    # the Jacobian matrix\n",
    "    H_k = np.array([[H_11, H_12, H_13], [H_21, H_22, H_23]])\n",
    "    H_k = np.asmatrix(H_k)\n",
    "    \n",
    "    # measurement Jacobian matrix for noise\n",
    "    M_k = np.diag([1, 1])\n",
    "\n",
    "    # 2. Compute Kalman Gain\n",
    "    \n",
    "    K_k = P_check@H_k.T@(inv(H_k@P_check@H_k.T + M_k@cov_y@M_k.T))\n",
    "\n",
    "    # 3. Correct predicted state (remember to wrap the angles to [-pi,pi])\n",
    "    y_check = measurementModel(x_check, lk)\n",
    "    # measurement as time k\n",
    "    y_meas = np.mat([rk, bk]).T\n",
    "    # corrected state estimation\n",
    "    x_check = x_check + K_k@(y_meas - y_check)\n",
    "\n",
    "    # 4. Correct covariance\n",
    "    P_check = ((np.eye(3)) - K_k@H_k)@P_check\n",
    "\n",
    "    return x_check, P_check\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prediction Step\n",
    "-----\n",
    "Now, implement the main filter loop, defining the prediction step of the EKF using the motion model provided:\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{\\check{x}}_k &= \\mathbf{f}\\left(\\mathbf{\\hat{x}}_{k-1}, \\mathbf{u}_{k-1}, \\mathbf{0} \\right) \\\\\n",
    "\\mathbf{\\check{P}}_k &= \\mathbf{F}_{k-1}\\mathbf{\\hat{P}}_{k-1}\\mathbf{F}_{k-1}^T + \\mathbf{L}_{k-1}\\mathbf{Q}_{k-1}\\mathbf{L}_{k-1}^T \\, .\n",
    "\\end{align}\n",
    "\n",
    "Where\n",
    "\n",
    "\\begin{align}\n",
    "\\mathbf{F}_{k-1} = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{x}_{k-1}}\\bigg|_{\\mathbf{\\hat{x}}_{k-1},\\mathbf{u}_{k},0}  \\, , \\, \\, \\, \\,\n",
    "\\mathbf{L}_{k-1} = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{w}_{k}}\\bigg|_{\\mathbf{\\hat{x}}_{k-1},\\mathbf{u}_{k},0} \\, .\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def motionModel(x_check, delta_t):\n",
    "    \"\"\"\n",
    "    This is the motion model for the given form which has the genral form of\n",
    "    x_k = x_k-1 + delta_t * f_k-1(x_k-1, u_k-1) + w_k; where,\n",
    "    f_k-1 = non-linear motion function, x_k-1 = is previous state, u_k-1 = external input (vehicle odometer ) giving \n",
    "    motion giving idea about state changes (from k-1 to k), w_k is the motion noise.\n",
    "    \"\"\"\n",
    "    F = np.array([[np.cos(x_check[2]), 0], [np.sin(x_check[2]), 0], [0, 1]])\n",
    "    U = np.array([[v[k]], [om[k]]])\n",
    "    x_check = x_check + delta_t * (F@U)\n",
    "    \n",
    "    #x_check[2] = wraptopi(x_check[2]) # wrap theta in [-pi, pi]\n",
    "    x_check = np.asmatrix(x_check).T\n",
    "    \n",
    "    return x_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = np.zeros((3, ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/moshiur/Research/Machine_Learning/opencv/venv/lib/python3.6/site-packages/ipykernel_launcher.py:32: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "shapes (1,3) and (1,3) not aligned: 3 (dim 1) != 1 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-e68a5a9ff0ef>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#P_check  = P_est[]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0mP_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     \u001b[0mP_check\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF_k\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mP_est\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mF_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mL_k\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mQ_km\u001b[0m\u001b[0;34m@\u001b[0m\u001b[0mL_k\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m     \u001b[0;31m#P_check = F_k.dot(P_est[k].dot(F_k.T)) + L_k.dot(Q_km.dot(L_k.T))\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Research/Machine_Learning/opencv/venv/lib/python3.6/site-packages/numpy/matrixlib/defmatrix.py\u001b[0m in \u001b[0;36m__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    216\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    217\u001b[0m             \u001b[0;31m# This promotes 1-D vectors to row vectors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 218\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mother\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'__rmul__'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mN\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mother\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdot\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: shapes (1,3) and (1,3) not aligned: 3 (dim 1) != 1 (dim 0)"
     ]
    }
   ],
   "source": [
    "#### 5. Main Filter Loop #######################################################################\n",
    "for k in range(1, len(t)):  # start at 1 because we've set the initial prediciton\n",
    "\n",
    "    delta_t = t[k] - t[k - 1]  # time step (difference between timestamps)\n",
    "    \n",
    "    x_check = np.zeros(3)\n",
    "    \n",
    "    # state of the previous time stamp, k-1\n",
    "    x_check[0] = x_est[k-1, 0]\n",
    "    x_check[1] = x_est[k-1, 1]\n",
    "    x_check[2] = x_est[k-1, 2]\n",
    "\n",
    "    # 1. Update state with odometry readings (remember to wrap the angles to [-pi,pi])\n",
    "    x_check = motionModel(x_check, delta_t)\n",
    "\n",
    "    # 2. Motion model Jacobian with respect to last state\n",
    "    #F_k = np.zeros([3, 3])\n",
    "    # Partial derivate of motion function f = [f1, f2, f3].T w.r.t to state x_k-1\n",
    "    df1_dx = [1, 0, -v[k-1] * np.sin(x_check[2])] # partial derivative of function f1 w.r.t x_k-1\n",
    "    df1_dy = [0, 1, v[k-1] * np.sin(x_check[2])] # partial derivative of function f2 w.r.t x_k-1\n",
    "    df1_dtheta = [0, 0, 1]\n",
    "    # Jacobian matrix for motion model\n",
    "    F_k = np.mat([df1_dx, df1_dy, df1_dtheta], object) # if I don't put object an error is thrown \n",
    "                                                # 'ValueError: setting an array element with a sequence' - need to check\n",
    "    #F_k = np.asmatrix(F_k).T\n",
    "    #F_k = np.array(\n",
    "       # [[1, 0, -delta_t * v[k - 1] * np.sin(x_check[2])], [0, 1, delta_t * v[k - 1] * np.cos(x_check[2])], [0, 0, 1]])\n",
    "    \n",
    "    # 3. Motion model jacobian with respect to noise\n",
    "    L_k = np.zeros([3, 2])\n",
    "    # partial derivate of W = [[cos(x_check[2]) * w_k. 0], [sin(x_check[2]) * w_k], [1, w_k]].T w.r.t. w_k\n",
    "    L_k = np.array([[np.cos(x_check[2]), 0], [np.sin(x_check[2]), 0], [0, 1]]) \n",
    "    \n",
    "\n",
    "    # 4. Propagate uncertainty\n",
    "    #P_check  = P_est[]\n",
    "    P_check = np.zeros([3, 3])\n",
    "    P_check = F_k@P_est[k-1]@F_k.T + L_k@Q_km@L_k.T\n",
    "    #P_check = F_k.dot(P_est[k].dot(F_k.T)) + L_k.dot(Q_km.dot(L_k.T))\n",
    "\n",
    "    # 5. Update state estimate using available landmark measurements\n",
    "    for i in range(len(r[k])):\n",
    "        x_check, P_check = measurement_update(l[i], r[k, i], b[k, i], P_check, x_check)\n",
    "\n",
    "    # Set final state predictions for timestep\n",
    "    x_est[k, 0] = x_check[0]\n",
    "    x_est[k, 1] = x_check[1]\n",
    "    x_est[k, 2] = x_check[2]\n",
    "    P_est[k, :, :] = P_check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.eye(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = np.eye(3) * 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3., 0., 0.],\n",
       "       [0., 3., 0.],\n",
       "       [0., 0., 3.]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot the resulting state estimates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e_fig = plt.figure()\n",
    "ax = e_fig.add_subplot(111)\n",
    "ax.plot(x_est[:, 0], x_est[:, 1])\n",
    "ax.set_xlabel('x [m]')\n",
    "ax.set_ylabel('y [m]')\n",
    "ax.set_title('Estimated trajectory')\n",
    "plt.show()\n",
    "\n",
    "e_fig = plt.figure()\n",
    "ax = e_fig.add_subplot(111)\n",
    "ax.plot(t[:], x_est[:, 2])\n",
    "ax.set_xlabel('Time [s]')\n",
    "ax.set_ylabel('theta [rad]')\n",
    "ax.set_title('Estimated trajectory')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Are you satisfied wth your results? The resulting trajectory should closely resemble the ground truth, with minor \"jumps\" in the orientation estimate due to angle wrapping. If this is the case, run the code below to produce your solution file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('submission.pkl', 'wb') as f:\n",
    "    pickle.dump(x_est, f, pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
